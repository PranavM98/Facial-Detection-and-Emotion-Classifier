{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "data=pd.read_csv(\"../../00_Data/01_Transformed_Data/face_detection_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin_Gil_0001.jpg</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>180</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerry_Kelly_0001.jpg</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>176</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eliane_Karp_0003.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>183</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vojislav_Kostunica_0006.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phil_Johnson_0001.jpg</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Filename  xmin  ymin  xmax  ymax  label\n",
       "0           Kevin_Gil_0001.jpg    71    69   180   178      1\n",
       "1         Gerry_Kelly_0001.jpg    72    71   176   175      1\n",
       "2         Eliane_Karp_0003.jpg    60    66   183   189      1\n",
       "3  Vojislav_Kostunica_0006.jpg    66    67   183   184      1\n",
       "4        Phil_Johnson_0001.jpg    64    64   186   186      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the tensor images\n",
    "images=[]\n",
    "\n",
    "#Storing the targets - boxes and labels\n",
    "targets=[]\n",
    "\n",
    "#Convert image to tensor\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "#Iterating over all images in dataset\n",
    "for i, r in data.iterrows():\n",
    "    d={}\n",
    "    x1= data.loc[i,'xmin']\n",
    "    y1= data.loc[i,'ymin']\n",
    "    x2= data.loc[i,'xmax']\n",
    "    y2= data.loc[i,'ymax']\n",
    "\n",
    "    boxes=[x1,y1,x2,y2]    \n",
    "    labels=1\n",
    "\n",
    "    d['boxes']=torch.FloatTensor(boxes).reshape(1,4)\n",
    "    d['labels']=labels\n",
    "    \n",
    "    targets.append(d)\n",
    "\n",
    "    # Recreate file-path\n",
    "    image_file_path = data.loc[i,'Filename']\n",
    "    image_file_path = '../../00_Data/01_Transformed_Data/Face_Detection_Images/' + image_file_path\n",
    "\n",
    "    img = cv2.imread(image_file_path)\n",
    "    a=convert_tensor(img)\n",
    "    images.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split_val = int(len(images) * 0.80)\n",
    "\n",
    "train_images = images[:train_val_split_val]\n",
    "train_targets = targets[:train_val_split_val]\n",
    "\n",
    "test_images = images[train_val_split_val:]\n",
    "test_targets = targets[train_val_split_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of entire dataset is: ', len(images))\n",
    "print('80-20 Split Train dataset size of: ', train_val_split_val)\n",
    "print('The length of Train dataset is: ', len(train_images))\n",
    "print('The length of Test dataset is: ', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(test_images, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict('../03_Model_Checkpoints/object_detection_checkpoint1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
